# Findings - Words and Punctuation
## Word Count
```{r}
df.both.words<-df.word %>%
  group_by(lit_type,title) %>%
  summarise(word_count = sum(count)) %>%
  arrange(desc(word_count))
df.lit.words<-subset(df.word,lit_type=="Book") %>%
  select(title,POS_word,count) %>%
  group_by(title) %>%
  summarise(word_count = sum(count)) %>%
  arrange(desc(word_count))
df.ff.words<-subset(df.word,lit_type=="Fanfiction") %>%
  select(title,POS_word,count) %>%
  group_by(title) %>%
  summarise(word_count = sum(count)) %>%
  arrange(desc(word_count))

# df.both.words$lit_type<-gsub("Book","Classic Literature",df.both.words$lit_type)
# p<-ggplot(data=df.both.words,aes(x=lit_type,y=word_count,fill=lit_type)) +
#   geom_bar(stat="identity",position="dodge2") +
#   theme_minimal()+labs(x='Literature Type',y='Word Count')
# p <- p + guides(fill=guide_legend(title="Literature Type"))
# p
  
fig.word.count <- plot_ly(x = df.lit.words$word_count, type = "box", quartilemethod="linear", name="Classic Literature") %>%
  add_trace(x = df.ff.words$word_count, quartilemethod="linear", name="Modern Fanfiction") %>%
  layout(title = "Word Counts by Literature Type")
fig.word.count
```
In our sample, the longest piece of classic literature is Aurora Leigh, at 89,224 words, while the shortest is the three little pigs, at 1,109, meaning our longest piece is almost 90 times the length of our shortest.

On the fanfiction side, our longest is The Marks we Make, at 270,559 words, while the shortest is That Awkward Moment When Your Whole Class Shows up At Your House, at 28,918, just shy of a tenth the length of our longest.  It does make up for it by having the longest title, however.

Although the extremes of our classic lit. sample are proportionally much more spread out, they're actually distributed much more evenly, as can be seen by the squat inner quartiles in the graph above.

There are certainly examples outside our sample of one group far surpassing the other in either direction: War and Peace is nearly 600,000 words, while the entire genre colloquially known as "CrackFic" is premised around being under 100.

```{r}
books_words <- books_words %>% arrange(desc(X2))
fanfic_words <- fanfic_words %>% arrange(desc(X_2))

#Gets a list of words that appear only in books or only in fanfiction
book.temp<-books_words %>% mutate(book_prop=X2/sum(books_words$X2,na.rm=TRUE))
fanfic.temp<-fanfic_words %>% mutate(fanfic_prop=X_2/sum(fanfic_words$X_2,na.rm=TRUE))

book.shared<-subset(book.temp,X1 %in% fanfic_words$X_1)
fanfic.shared<-subset(fanfic.temp,X_1 %in% books_words$X1)


book.shared$fanfic_prop <- fanfic.shared$fanfic_prop[match(book.shared$X1,fanfic.shared$X_1)]
lit.shared<-book.shared

#Higher dif = More Popular in Books
lit.shared$dif<-lit.shared$book_prop-lit.shared$fanfic_prop
lit.shared<-lit.shared %>% arrange(desc(dif))
shared.length<-length(lit.shared$X1)

book.popular<-lit.shared$X1[1:10]
fanfic.popular<-lit.shared$X1[(shared.length-9):shared.length-1]

cbind(book.popular,fanfic.popular)

#Unique Words to each group
# `%!in%` <- Negate(`%in%`)
# subset(book.temp,X1 %!in% fanfic_words$X_1)
# subset(fanfic.temp,X_1 %!in% books_words$X1)


```


## Punctuation

```{r echo = FALSE}
p<-ggplot(data=POS_punct,aes(x=POS_punctuation , y=proportion,fill=lit_type))+
  geom_bar(stat = 'identity',position = 'dodge')+
  theme_minimal()+ scale_y_continuous(expand=expansion(mult=c(0,0.1)))+labs(x='part of speech',y='proportion')
p <- p + guides(fill=guide_legend(title="Literature Type"))
p
```
Above we can see the punctuation used

It's worth nothing that the method we used for tokenizing punctuation results in a lot of simplification: colons, semi-colons, and ellipses are all classified as ':'.  Exclamation marks and periods are considered the same.  Despite this, there's still a bit that can be gleaned from this graphic: classic literature has a higher proportion of commas and partial sentence breaks, which might point towards more compound sentences, and the hashtag only appears in our fanfiction sample.